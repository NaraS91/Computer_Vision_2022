{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Fish Classification\n",
    "\n",
    "Created by Athanasios Vlontzos and Wenjia Bai\n",
    "\n",
    "In this coursework, you will be exploring the application of convolutional neural networks for image classification tasks. As opposed to standard applications such as object or face classification, we will be dealing with a slightly different domain, fish classification for precision fishing.\n",
    "\n",
    "In precision fishing, engineers and fishmen collaborate to extract a wide variety of information about the fish, their species and wellbeing etc. using data from satellite images to drones surveying the fisheries. The goal of precision fishing is to provide the marine industry with information to support their decision making processes.\n",
    "\n",
    "Here your will develop an image classification model that can classify fish species given input images. It consists of two tasks. The first task is to train a model for the following species:\n",
    "- Black Sea Sprat\n",
    "- Gilt-Head Bream\n",
    "- Shrimp\n",
    "- Striped Red Mullet\n",
    "- Trout\n",
    "\n",
    "The second task is to finetune the last layer of the trained model to adapt to some new species, including:\n",
    "- Hourse Mackerel\n",
    "- Red Mullet\n",
    "- Red Sea Bream\n",
    "- Sea Bass\n",
    "\n",
    "You will be working using a large-scale fish dataset [1].\n",
    "\n",
    "[1] O. Ulucan, D. Karakaya and M. Turkan. A large-scale dataset for fish segmentation and classification. Innovations in Intelligent Systems and Applications Conference (ASYU). 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data.\n",
    "\n",
    "[Download the Data from here -- make sure you access it with your Imperial account.](https://imperiallondon-my.sharepoint.com/:f:/g/personal/av2514_ic_ac_uk/EkA9HyXVvgdFoLI4P_IfO1cBO_CsvY1KN4NE8iuD-s_VlA?e=Ip03rF)\n",
    "\n",
    "It is a ~2.5GB file. You can save the images and annotations directories in the same directory as this notebook or somewhere else.\n",
    "\n",
    "The fish dataset contains 9 species of fishes. There are 1,000 images for each fish species, named as %05d.png in each subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data. (15 Points)\n",
    "\n",
    "- Complete the dataset class with the skeleton below.\n",
    "- Add any transforms you feel are necessary.\n",
    "\n",
    "Your class should have at least 3 elements\n",
    "- An ```__init__``` function that sets up your class and all the necessary parameters.\n",
    "- An ```__len__``` function that returns the size of your dataset.\n",
    "- An ```__getitem__``` function that given an index within the limits of the size of the dataset returns the associated image and label in tensor form.\n",
    "\n",
    "You may add more helper functions if you want.\n",
    "\n",
    "In this section we are following the Pytorch [dataset](https://pytorch.org/vision/stable/datasets.html) class structure. You can take inspiration from their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\repos\\Computer_Vision_2022\\coursework_02\\coursework_02.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=18'>19</a>\u001b[0m LENDATA \u001b[39m=\u001b[39m \u001b[39m5000\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=19'>20</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=20'>21</a>\u001b[0m idxs_train, idxs_test \u001b[39m=\u001b[39m split_train_test(LENDATA,\u001b[39m0.8\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=22'>23</a>\u001b[0m \u001b[39m# Implement the dataset class\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=23'>24</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFishDataset\u001b[39;00m(Dataset):\n",
      "\u001b[1;32md:\\Documents\\repos\\Computer_Vision_2022\\coursework_02\\coursework_02.ipynb Cell 5'\u001b[0m in \u001b[0;36msplit_train_test\u001b[1;34m(lendata, percentage)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=14'>15</a>\u001b[0m shuffeled_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(LENDATA)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=15'>16</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(shuffeled_indices)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/repos/Computer_Vision_2022/coursework_02/coursework_02.ipynb#ch0000004?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m shuffeled_indices[:(lendata \u001b[39m*\u001b[39;49m percentage)], shuffeled_indices[(lendata \u001b[39m*\u001b[39m percentage):]\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "# We will start by building a dataset class using the following 5 species of fishes\n",
    "Multiclass_labels_correspondances = {\n",
    "    'Black Sea Sprat': 0,\n",
    "    'Gilt-Head Bream': 1,\n",
    "    'Shrimp': 2,\n",
    "    'Striped Red Mullet': 3,\n",
    "    'Trout': 4\n",
    "}\n",
    "\n",
    "# The 5 species will contain 5,000 images in total.\n",
    "# Let us split the 5,000 images into training (80%) and test (20%) sets\n",
    "def split_train_test(lendata, percentage=0.8):\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "\n",
    "    shuffeled_indices = np.arange(LENDATA)\n",
    "    np.random.shuffle(shuffeled_indices)\n",
    "    return shuffeled_indices[:int(lendata * percentage)], shuffeled_indices[int(lendata * percentage):]\n",
    "\n",
    "LENDATA = 5000\n",
    "np.random.seed(42)\n",
    "idxs_train, idxs_test = split_train_test(LENDATA,0.8)\n",
    "\n",
    "# Implement the dataset class\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 path_to_images,\n",
    "                 idxs_train,\n",
    "                 idxs_test,\n",
    "                 transform_extra=None,\n",
    "                 img_size=128,\n",
    "                 train=True):\n",
    "        # path_to_images: where you put the fish dataset\n",
    "        # idxs_train: training set indexes\n",
    "        # idxs_test: test set indexes\n",
    "        # transform_extra: extra data transform\n",
    "        # img_size: resize all images to a standard size\n",
    "        # train: return training set or test set\n",
    "        \n",
    "        # Load all the images and their labels\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        self.dataset = {\n",
    "            'test': list(),\n",
    "            'train': list(),\n",
    "        }\n",
    "\n",
    "        self.index_mapping = [0] * (len(idxs_test) + len(idxs_train))\n",
    "\n",
    "        i = 0\n",
    "        for (species, label) in Multiclass_labels_correspondances:\n",
    "            path = '{}/{}'.format(path_to_images, species)\n",
    "            for file in glob.glob(path + '/*.png'):\n",
    "                image = Image.open(file)\n",
    "                if i in idxs_test:\n",
    "                    self.index_map[i] = ('test', len(self.dataset['test']))\n",
    "                    self.dataset['test'].append((image.copy(), label))\n",
    "                else:\n",
    "                    self.index_map[i] = ('train', len(self.dataset['train']))\n",
    "                    self.dataset['train'].append((image.copy(), label))\n",
    "                image.close()\n",
    "                i += 1\n",
    "        \n",
    "        # Resize all images to a standard size\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        for (purpose, images) in self.dataset:\n",
    "            self.dataset[purpose] = [(image.resize(img_size, img_size), label) for (image, label) in images]\n",
    "        \n",
    "        # Extract the images and labels with the specified file indexes      \n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        if train:\n",
    "            return self.dataset['train']\n",
    "        else:\n",
    "            return self.dataset['test']\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of samples\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        \n",
    "        raise len(self.dataset['train']) + len(self.dataset['test'])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Get an item using its index\n",
    "        # Return the image and its label\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        (purpose, index) = self.index_mapping[idx]\n",
    "        raise self.dataset[purpose][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data. (15 Points)\n",
    "\n",
    "### Step 2.1: Data visualisation. (5 points)\n",
    "\n",
    "- Plot data distribution, i.e. the number of samples per class.\n",
    "- Plot 1 sample from each of the five classes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "img_path = './archive/Fish_Dataset/Fish_Dataset'\n",
    "dataset  = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=True)\n",
    "\n",
    "# Plot the number of samples per class\n",
    "#### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Plot 1 sample from each of the five classes in the training set\n",
    "#### ADD YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Discussion. (10 points)\n",
    "\n",
    "* Is the dataset balanced?\n",
    "\n",
    "* Can you think of 3 ways to make the dataset balanced if it is not?\n",
    "\n",
    "* Is the dataset already pre-processed? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD YOUR RESPONSE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multiclass classification. (55 points)\n",
    "In this section we will try to make a multiclass classifier to determine the species of the fish.\n",
    "\n",
    "### Step 3.1: Define the model. (15 points)\n",
    "\n",
    "Design a neural network which consists of a number of convolutional layers and a few fully connected ones at the end.\n",
    "\n",
    "The exact architecture is up to you but you do NOT need to create something complicated. For example, you could design a LeNet insprired network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dims = 1):\n",
    "        super(Net, self).__init__()\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "\n",
    "        return x\n",
    "\n",
    "# Since most of you use laptops, you may use CPU for training.\n",
    "# If you have a good GPU, you can set this to 'gpu'.\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Define the training parameters. (10 points)\n",
    "\n",
    "- Loss function\n",
    "- Optimizer\n",
    "- Learning Rate\n",
    "- Number of iterations\n",
    "- Batch Size\n",
    "- Other relevant hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "model =\n",
    "\n",
    "# Loss function\n",
    "criterion =\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr =\n",
    "optimizer =\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs =\n",
    "\n",
    "# Training batch size\n",
    "train_batch_size =\n",
    "\n",
    "# Based on the FishDataset, use the PyTorch DataLoader to load the data during model training\n",
    "train_dataset =\n",
    "train_dataloader =\n",
    "test_dataset =\n",
    "test_dataloader ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Train the model. (15 points)\n",
    "\n",
    "Complete the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    loss_curve = []\n",
    "    \n",
    "    for imgs, labs in train_dataloader:\n",
    "        # Get a batch of training data and train the model\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        \n",
    "        loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f} ---'.format(epoch + 1, np.array(loss_curve).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Deploy the trained model onto the test set. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "#### ADD YOUR CODE HERE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5: Evaluate the performance of the model and visualize the confusion matrix. (5 points)\n",
    "\n",
    "You can use sklearns related function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Finetune your classifier. (15 points)\n",
    "\n",
    "In the previous section, you have built a pretty good classifier for certain species of fish. Now we are going to use this trained classifier and adapt it to classify a new set of species:\n",
    "\n",
    "    'Hourse Mackerel\n",
    "    'Red Mullet',\n",
    "    'Red Sea Bream'\n",
    "    'Sea Bass'\n",
    "\n",
    "### Step 4.1: Set up the data for new species. (2 points)\n",
    "Overwrite the labels correspondances so they only incude the new classes and regenerate the datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Multiclass_labels_correspondances ={\n",
    "    'Hourse Mackerel': 0,\n",
    "    'Red Mullet': 1,\n",
    "    'Red Sea Bream': 2,\n",
    "    'Sea Bass': 3}\n",
    "\n",
    "LENDATA = 4000\n",
    "idxs_train,idxs_test = split_train_test(LENDATA, 0.8)\n",
    "\n",
    "# Dataloaders\n",
    "#### ADD YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Freeze the weights of all previous layers of the network except the last layer. (5 points)\n",
    "\n",
    "You can freeze them by setting the gradient requirements to ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def freeze_till_last(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "freeze_till_last(model)\n",
    "# Modify the last layer. This layer is not freezed.\n",
    "#### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Loss function\n",
    "criterion =\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr =\n",
    "optimizer =\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs =\n",
    "\n",
    "# Training batch size\n",
    "train_batch_size ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Train and test your finetuned model. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finetune the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Deploy the model on the test set\n",
    "#### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Evaluate the performance\n",
    "#### ADD YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Did finetuning work? Why did we freeze the first few layers? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD YOUR RESPONSE HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
